# 什么是逻辑回归？（Logistic Regression）

逻辑回归（Logistic Regression）是一种广泛应用于二分类问题的**广义线性模型**，它通过对线性组合结果进行**逻辑函数（sigmoid）**变换，将连续值映射到 $[0,1]$ 区间，进而解释为事件发生的概率。与线性回归不同，逻辑回归能够保证预测值落在合理的概率区间内，并基于**最大似然估计**来求解模型参数。其应用涵盖金融风险评估、医疗诊断、市场营销响应预测等领域。

# 定义与作用

- 逻辑回归用于**分类任务**，特别是二分类问题，通过估计事件发生的概率来进行决策。如果记因变量 $Y\in\{0,1\}$，自变量（特征）向量为 $\mathbf{x}$，则模型的目标是学习函数

$$
p(x)=P(Y=1∣x)
$$

并根据阈值（如 0.5）进行类别判定

- 在统计学中，逻辑回归也称为**二项式 Logit 模型**，它是广义线性模型（Generalized Linear Model, GLM）家族的一员，适用于因变量为二项分布的场景 

## 为什么不用普通的线性回归做分类？

你可能会想，既然是线性模型，为什么不直接用线性回归来做分类呢？比如，对于一个二分类问题，我们可以将一个类别标记为 0，另一个标记为 1，然后用线性回归模型去拟合数据。

这样做会有几个问题：

1. **输出值超出范围：** 线性回归的输出值是连续的，可以超出 [0, 1] 的范围，而概率值必须在 [0, 1] 之间。
2. **不适合解释为概率：** 线性回归的输出值很难直接解释为属于某个类别的概率。
3. **对异常值敏感：** 线性回归对异常值比较敏感，可能会导致分类边界的偏差。

**逻辑回归的核心思想：引入 Sigmoid 函数**

为了解决上述问题，逻辑回归引入了一个**Sigmoid 函数**（也称为 Logistic 函数），将线性回归的输出值映射到 [0, 1] 的概率范围。

## 逻辑回归的预测过程

对于给定的输入特征向量 x，计算线性组合 $z=w^Tx+b$。

将 z 输入到 Sigmoid 函数中，得到预测的概率值 $\hat{p} =σ(z)$。

根据设定的阈值（通常是 0.5），将概率值转换为最终的类别预测：

- 如果$ \hat {p}≥阈值$，则预测为正类 (1)。
- 如果$ \hat {p}<阈值$，则预测为负类 (0)。

## 损失函数

为了训练逻辑回归模型，我们需要定义一个损失函数来衡量模型的预测结果与真实标签之间的差距。对于二分类问题，常用的损失函数是**对数损失函数 (Log Loss) 或二元交叉熵 (Binary Cross-Entropy)**：
$$
J(w,b)=− 
\frac{1}{m}
​
  

∑_{i=1}^{m}
​
 [y 
^{(i)}
 log( 
\hat{p}^{(i)}
 )+(1−y^{(i)}
 )log(1− 
\hat{p}^{(i)})]
$$
其中：

- $m$ 是训练样本的数量。
- $y^{(i)}$ 是第 i 个样本的真实标签（0 或 1）。
- $ \hat{p}^{(i)}=σ(w^Tx^{(i)}+b) $是模型对第 i 个样本预测为正类的概率

**损失函数的直观理解：**

- 如果真实标签$ y^{(i)}=1$，我们希望$\hat{p}^{(i)}$ 尽可能接近 1，此时$ −log(\hat{p}^{(i)})$ 接近 0，损失较小。如果 $\hat{p}^{(i)}$接近 0，则 $ −log(\hat{p}^{(i)})$趋于无穷大，损失很大。
- 如果真实标签 $ y^{(i)}=1$，我们希望 $\hat{p}^{(i)}$ 尽可能接近 0，此时$ −log(\hat{p}^{(i)})$接近 0，损失较小。如果 $\hat{p}^{(i)}$ 接近 1，则$ −log(\hat{p}^{(i)})$趋于无穷大，损失很大。

我们的目标是找到最优的权重向量 w 和偏置项 b，使得损失函数 J(w,b) 最小化。常用的优化算法包括：

- **梯度下降 (Gradient Descent):** 通过迭代地计算损失函数关于参数的梯度，并沿着梯度的反方向更新参数，逐步逼近最优解。
- **牛顿法 (Newton's Method) 和拟牛顿法 (Quasi-Newton Methods):** 这些方法利用了损失函数的二阶导数信息，通常收敛速度更快。
- **L-BFGS (Limited-memory Broyden–Fletcher–Goldfarb–Shanno):** 一种常用的拟牛顿法。

# 数学推导

## 线性预测器与逻辑函数

1. **线性组合**
    构造线性预测器（线性分数）：

$$
z=β 
_0
​
 +β 
_1
​
 x 
_1
​
 +⋯+β 
_m
​
 x 
_m
​
 =β 
^⊤
 x
$$

其中 $\boldsymbol\beta$ 为待估参数向量，$\mathbf{x}$ 为扩展后包含常数项的特征向量

2. 逻辑函数（Sigmoid）

将线性组合 $z$ 映射到概率空间：
$$
σ(z)= \frac{1}{1+e^{-z}} ⟹ p(x)=σ(β^⊤x)
$$
该函数具有“S”型曲线特征，可将任意实数压缩至 $(0,1)$ 区间